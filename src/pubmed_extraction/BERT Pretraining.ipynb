{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install scispacy\n",
    "#!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.3/en_core_sci_sm-0.2.3.tar.gz\n",
    "#!pip install nltk\n",
    "#!pip install tensorflow\n",
    "#!pip install --user sentencepiece\n",
    "    \n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "#import nltk\n",
    "import random\n",
    "import logging\n",
    "import sentencepiece as spm\n",
    "#import scispacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tail -n 1 pubmed_dump.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "SENT = \"The study was carried out in a borough of London where a there is a disparity of wealth and a large ethnic minority population and therefore may be different to many other areas of the UK. However, the findings have similarities to those of other UK studies examining the patient perspective of provision and uptake of care (17,19), which agree that GPs could provide more information and be more proactive in respect of preconception care provision. In addition, we found that GPs were more likely to provide preconception care to women with medical conditions, and this targeted approach highlighted issues similar to those found by Mortagy et al. (46) who interviewed GPs and secondary care health professionals focusing on women with diabetes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_sci_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(SENT.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from tqdm import tqdm\n",
    "total_lines = 15809286 # counted via wc -l\n",
    "import multiprocessing as mp\n",
    "import uuid\n",
    "\n",
    "NUM_WORKERS = 19\n",
    "\n",
    "def worker(job_q):\n",
    "    with open(f\"data/{uuid.uuid4()}\", \"w+\") as file_obj:\n",
    "        while True:\n",
    "            paragraph = job_q.get()\n",
    "\n",
    "            if paragraph is None:\n",
    "                break\n",
    "\n",
    "            processed_text = nlp(paragraph.lower())\n",
    "            file_obj.write(processed_text.text.strip()+'\\n')\n",
    "\n",
    "job_queue = mp.Queue(maxsize=NUM_WORKERS)\n",
    "\n",
    "pool = mp.Pool(NUM_WORKERS, initializer=worker, initargs=(job_queue,))\n",
    "\n",
    "with open(\"xaa\", encoding='utf-8') as input:\n",
    "    for paragraph in tqdm(input, total=total_lines):\n",
    "        job_queue.put(paragraph)\n",
    "\n",
    "    for _ in range(NUM_WORKERS):\n",
    "        job_queue.put(None)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PREFIX = \"tokenizer\" #@param {type: \"string\"}\n",
    "VOC_SIZE = 32000 #@param {type:\"integer\"}\n",
    "SUBSAMPLE_SIZE = 20000000 #@param {type:\"integer\"}\n",
    "NUM_PLACEHOLDERS = 256 #@param {type:\"integer\"}\n",
    "PRC_DATA_FPATH = \"data/pubmed_processed.txt\"\n",
    "\n",
    "SPM_COMMAND = ('--input={} --model_prefix={} '\n",
    "               '--vocab_size={} --input_sentence_size={} '\n",
    "               '--shuffle_input_sentence=true ' \n",
    "               '--bos_id=-1 --eos_id=-1 --num_threads=8').format(\n",
    "               PRC_DATA_FPATH, MODEL_PREFIX, \n",
    "               VOC_SIZE - NUM_PLACEHOLDERS, SUBSAMPLE_SIZE)\n",
    "\n",
    "spm.SentencePieceTrainer.Train(SPM_COMMAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcase = \"Colorless geothermal substations are generating furiously\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 100 tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentencepiece_vocab(filepath):\n",
    "  voc = []\n",
    "  with open(filepath, encoding='utf-8') as fi:\n",
    "    for line in fi:\n",
    "      voc.append(line.split(\"\\t\")[0])\n",
    "  # skip the first <unk> token\n",
    "  voc = voc[1:]\n",
    "  return voc\n",
    "\n",
    "snt_vocab = read_sentencepiece_vocab(\"{}.vocab\".format(MODEL_PREFIX))\n",
    "print(\"Learnt vocab size: {}\".format(len(snt_vocab)))\n",
    "print(\"Sample tokens: {}\".format(random.sample(snt_vocab, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we may observe, SentencePiece does quite the opposite to WordPiece. From the documentation:\n",
    "\n",
    "SentencePiece first escapes the whitespace with a meta-symbol \"▁\" (U+2581) as follows:\n",
    "\n",
    "Hello▁World.\n",
    "\n",
    "Then, this text is segmented into small pieces, for example:\n",
    "\n",
    "[Hello] [▁Wor] [ld] [.]\n",
    "\n",
    "Subwords which occur after whitespace (which are also those that most words begin with) are prepended with '▁', while others are unchanged. This excludes subwords which only occur at the beginning of sentences and nowhere else. These cases should be quite rare, however.\n",
    "\n",
    "So, in order to obtain a vocabulary analogous to WordPiece, we need to perform a simple conversion, removing \"▁\" from the tokens that contain it and adding \"##\" to the ones that don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sentencepiece_token(token):\n",
    "    if token.startswith(\"▁\"):\n",
    "        return token[1:]\n",
    "    else:\n",
    "        return \"##\" + token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vocab = list(map(parse_sentencepiece_token, snt_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_symbols = [\"[PAD]\",\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"]\n",
    "bert_vocab = ctrl_symbols + bert_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vocab += [\"[UNUSED_{}]\".format(i) for i in range(VOC_SIZE - len(bert_vocab))]\n",
    "print(len(bert_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOC_FNAME = \"vocab.txt\" #@param {type:\"string\"}\n",
    "\n",
    "with open(VOC_FNAME, \"w\") as fo:\n",
    "  for token in bert_vocab:\n",
    "    fo.write(token+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = tokenization.FullTokenizer(VOC_FNAME)\n",
    "bert_tokenizer.tokenize(testcase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
